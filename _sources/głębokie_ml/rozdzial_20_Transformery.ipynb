{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWE41UV_Pvcf"
   },
   "source": [
    "### Transformery\n",
    "\n",
    "0. Twórcy: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin,\n",
    "Publikacja: \"Attention Is All You Need\", Advances in Neural Information Processing Systems (NeurIPS, 2017),\n",
    "arXiv:1706.03762\n",
    "\n",
    "1. Definicja. Transformery to architektura sieci neuronowych zaprojektowana do przetwarzania sekwencji danych.\n",
    "\n",
    "2. Mechanizm uwagi (\"attention\"). Transformery opierają się na mechanizmie \"self-attention\", który pozwala modelowi skupiać się na różnych częściach sekwencji wejściowej, niezależnie od ich odległości.\n",
    "\n",
    "3. Brak rekurencji: W przeciwieństwie do RNN i LSTM, transformery nie używają rekurencji, co przyspiesza obliczenia i ułatwia równoległe przetwarzanie.\n",
    "\n",
    "4. Skalowalność. Transformery są wysoce skalowalne i mogą być łatwo dostosowywane do dużych zbiorów danych, co czyni je idealnymi do zadań takich jak tłumaczenie maszynowe czy generowanie tekstu.\n",
    "\n",
    "5. Encoder-Decoder. Standardowy transformer składa się z dwóch głównych części:\n",
    "\n",
    "- Encoder: Przetwarza sekwencję wejściową.\n",
    "\n",
    "- Decoder: Generuje sekwencję wyjściową na podstawie zakodowanej reprezentacji.\n",
    "\n",
    "6. \"Positional Encoding\". Ponieważ transformery nie mają wbudowanej informacji o kolejności elementów w sekwencji, dodaje się kodowanie pozycyjne, aby zachować informację o pozycji.\n",
    "\n",
    "7. Zastosowania. Transformery są używane w zadaniach takich jak tłumaczenie maszynowe, generowanie tekstu (np. GPT), klasyfikacja tekstu (np. BERT) i analiza obrazów (np. Vision Transformers).\n",
    "\n",
    "8. Efektywność. Dzięki równoległemu przetwarzaniu sekwencji Transformery są szybsze w trenowaniu niż RNN/LSTM, zwłaszcza na sprzęcie GPU/TPU.\n",
    "\n",
    "9. \"Pre-training\" i \"fine-tuning\". Transformery są często wstępnie trenowane na dużych zbiorach danych, a następnie dostrajane do konkretnych zadań (np. BERT, GPT).\n",
    "\n",
    "10. Dominacja. Transformery zrewolucjonizowały przetwarzanie języka naturalnego (NLP) i stały się podstawą wielu nowoczesnych modeli, takich jak GPT, BERT czy T5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 335078,
     "status": "ok",
     "timestamp": 1739148073901,
     "user": {
      "displayName": "Maciej Janowicz",
      "userId": "09531894793951009605"
     },
     "user_tz": -60
    },
    "id": "R5z06RE-Puja",
    "outputId": "6c1ed658-7c8b-4648-8f26-abc5a12dbf9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ transformer_block_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,656</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m640,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ transformer_block_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m10,656\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650,689</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m650,689\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650,689</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m650,689\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 137ms/step - accuracy: 0.7533 - loss: 0.4904 - val_accuracy: 0.8616 - val_loss: 0.3168\n",
      "Epoch 2/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 160ms/step - accuracy: 0.9137 - loss: 0.2153 - val_accuracy: 0.8617 - val_loss: 0.3306\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.8625 - loss: 0.3321\n",
      "Test Accuracy: 0.8617\n"
     ]
    }
   ],
   "source": [
    "# Przykład\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Parametry\n",
    "vocab_size = 20000  # Liczba słów w słowniku\n",
    "maxlen = 200        # Maksymalna długość sekwencji\n",
    "embed_dim = 32      # Wymiar embeddingu\n",
    "num_heads = 2       # Liczba głów w mechanizmie uwagi\n",
    "ff_dim = 32         # Wymiar warstwy feed-forward\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Wczytanie danych IMDB\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Przygotowanie danych (padding)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# Definicja warstwy Transformer Encoder\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training = False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Budowa modelu\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, embed_dim)(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)(embedding_layer)\n",
    "pooling_layer = GlobalMaxPooling1D()(transformer_block)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(pooling_layer)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# Trenowanie modelu\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Ocena modelu\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jgyGr5GUE9B"
   },
   "source": [
    "### Uwagi\n",
    "\n",
    "1. Dane. Używamy zbioru danych IMDB, który zawiera 50 000 recenzji filmowych oznaczonych jako pozytywne lub negatywne.\n",
    "\n",
    "2. Przygotowanie danych. Sekwencje tekstowe są przekształcane na sekwencje liczb całkowitych i dopełniane do stałej długości (maxlen).\n",
    "\n",
    "3. TransformerBlock: Definiujemy warstę Transformer Encoder (poprzez określenie odpowiedniej klasy), która składa się z mechanizmu \"Multi-Head Attention\", warstwy \"feed-forward\" i normalizacji.\n",
    "\n",
    "4. Model. Model składa się z warstwy osadzenia (\"embeddingu\"), warstwy Transformer, globalnego \"max pooling\" i warstwy wyjściowej.\n",
    "\n",
    "5. Trening. Model jest trenowany przez dwie epoki z użyciem optymalizatora Adam i funkcji straty binary cross-entropy.\n",
    "\n",
    "6. Wyniki. Model osiąga dokładność (accuracy) na zbiorze testowym, która jest wypisywana na końcu.\n",
    "\n",
    "### Dlaczego Transformery są lepsze niż LSTM/RNN:\n",
    "\n",
    "1. Równoległe przetwarzanie. Transformery przetwarzają całe sekwencje równolegle, co znacznie przyspiesza obliczenia.\n",
    "\n",
    "2. Długie zależności. Mechanizm self-attention pozwala Transformatorom efektywnie modelować długoterminowe zależności w danych.\n",
    "\n",
    "3. Skalowalność. Transformery są łatwe do skalowania na dużych zbiorach danych i potężnym sprzęcie (GPU/TPU).\n",
    "\n",
    "4. Uniwersalność. Transformery są stosowane nie tylko w NLP, ale także w przetwarzaniu obrazów, dźwięku i innych dziedzinach."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOa8J9t6Rg3yhgHkI47plD0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
