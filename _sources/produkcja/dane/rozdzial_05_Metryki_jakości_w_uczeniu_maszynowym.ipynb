{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metryki jakości w uczeniu maszynowym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6-B1PZZOcc2"
   },
   "source": [
    "###Proces uczenia maszynowego i oceny modeli.\n",
    "\n",
    "1. Czynności wykonywane podczas uczenia algorytmu\n",
    "\n",
    "A. Wstępne przetwarzanie danych:\n",
    "- Czyszczenie danych: usuwanie lub uzupełnianie brakujących wartości, eliminacja błędnych rekordów i odstających obserwacji\n",
    "- Normalizacja i standaryzacja: sprowadzenie zmiennych do wspólnej skali (np. 0-1 lub rozkładu normalnego)\n",
    "- Kodowanie zmiennych kategorialnych: zamiana na wartości numeryczne (one-hot encoding, label encoding)\n",
    "- Redukcja wymiarowości: wybór najważniejszych cech lub tworzenie nowych (analiza głównych składowych, selekcja cech)\n",
    "- Podział na zbiór treningowy, walidacyjny i testowy (najczęściej w proporcjach 60-20-20 lub 70-15-15)\n",
    "\n",
    "B. Wybór modelu:\n",
    "- Analiza charakteru problemu (klasyfikacja, regresja, klastrowanie)\n",
    "- Ocena dostępnych danych (liczba próbek, wymiarowość, typ zmiennych)\n",
    "- Wybór odpowiedniego algorytmu (np. drzewa decyzyjne, sieci neuronowe, SVM)\n",
    "- Określenie hiperparametrów modelu\n",
    "- Rozważenie ograniczeń obliczeniowych i czasowych\n",
    "\n",
    "C. Uczenie:\n",
    "- Trenowanie modelu na zbiorze treningowym\n",
    "- Walidacja krzyżowa (\"cross-validation\")\n",
    "- Dostrajanie hiperparametrów (\"grid search\", \"random search\")\n",
    "- Monitorowanie procesu uczenia (śledzenie krzywych uczenia)\n",
    "- Zapobieganie przeuczeniu (regularyzacja, wczesne zatrzymanie)\n",
    "\n",
    "D. Ocena modelu:\n",
    "- Testowanie na niezależnym zbiorze testowym\n",
    "- Obliczanie metryk wydajności\n",
    "- Analiza błędów i przypadków problematycznych\n",
    "- Interpretacja wyników\n",
    "- Iteracyjne udoskonalanie modelu\n",
    "\n",
    "2. Wskaźniki oceny modeli\n",
    "\n",
    "A. Dokładność (Accuracy):\n",
    "- Stosunek poprawnych przewidywań do wszystkich przypadków\n",
    "- Wzór: (TP + TN) / (TP + TN + FP + FN)\n",
    "- Zalety: łatwa interpretacja\n",
    "- Wady: może być myląca przy niezbalansowanych klasach\n",
    "- Zastosowanie: problemy z dobrze zbalansowanymi klasami\n",
    "\n",
    "B. Precyzja (Precision):\n",
    "- Stosunek prawdziwie pozytywnych do wszystkich przewidzianych jako pozytywne\n",
    "- Wzór: TP / (TP + FP)\n",
    "- Pokazuje, jaki procent pozytywnych przewidywań był faktycznie trafny\n",
    "- Ważna gdy fałszywie pozytywne wyniki są kosztowne\n",
    "- Zastosowanie: systemy rekomendacji, diagnostyka medyczna\n",
    "\n",
    "C. Czułość (Recall):\n",
    "- Stosunek prawdziwie pozytywnych do wszystkich faktycznie pozytywnych przypadków\n",
    "- Wzór: TP / (TP + FN)\n",
    "- Pokazuje, jaki procent faktycznie pozytywnych przypadków został wykryty\n",
    "- Istotna gdy nie możemy przeoczyć pozytywnych przypadków\n",
    "- Zastosowanie: wykrywanie oszustw, diagnostyka chorób\n",
    "\n",
    "D. Wskaźnik F1:\n",
    "- Średnia harmoniczna precyzji i czułości\n",
    "- Wzór:\n",
    "  F1 = 2 * (Precyzja * Czułość) / (Precyzja + Czułość)\n",
    "- Ukazuje zarówno precyzję, jak i czułość\n",
    "- Dobry wskaźnik dla niezbalansowanych zbiorów danych\n",
    "- Pozwala na ocenę modelu za pomocą jednego wskaźnika\n",
    "\n",
    "E. Pole pod krzywą ROC (AUC-ROC):\n",
    "- Krzywa ROC pokazuje relację między TPR (czułość) a FPR\n",
    "- TPR = TP / (TP + FN)\n",
    "- FPR = FP / (TN + FP)\n",
    "- Mierzy całościową zdolność modelu do rozróżniania klas\n",
    "- Wartości od 0 do 1 (im bliżej 1, tym lepiej)\n",
    "- Niewrażliwe na niezbalansowanie klas\n",
    "- Pozwala porównywać różne modele\n",
    "\n",
    "F. Krzywa \"lift\"\n",
    "\n",
    "Krzywa \"lift\" jest to narzędzie wizualizacji, które pomaga ocenić skuteczność modelu predykcyjnego w porównaniu do losowego wyboru. Pokazuje ona, o ile lepiej model radzi sobie z identyfikacją pozytywnych przypadków w porównaniu do przypadkowego, losowego wyboru.\n",
    "\n",
    "F1. Definicja\n",
    "\n",
    "- \"Lift\" to stosunek między odsetkiem pozytywnych wyników w wybranej grupie a odsetkiem pozytywnych wyników w całej populacji.\n",
    "\n",
    "F2. Interpretacja\n",
    "\n",
    "- \"Lift\" = 1 oznacza, że model nie jest lepszy od losowego wyboru.\n",
    "- \"Lift\" > 1 wskazuje, że model działa lepiej niż losowy wybór.\n",
    "\n",
    "- Im wyższa wartość \"liftu\", tym lepszy model\n",
    "\n",
    "F3. Zastosowanie\n",
    "\n",
    "- Marketing: optymalizacja kampanii reklamowych\n",
    "- Sprzedaż: identyfikacja potencjalnych klientów\n",
    "- Analiza ryzyka: wykrywanie fraudów\n",
    "- Medycyna: przewidywanie ryzyka chorób\n",
    "\n",
    "F4. Przykład.\n",
    "Załóżmy, że bank chce zidentyfikować klientów, którzy najprawdopodobniej skorzystają z nowej oferty kredytowej. Średni współczynnik odpowiedzi w populacji wynosi 5%. Jeśli model wskazuje grupę, w której współczynnik odpowiedzi wynosi 15%, \"lift\" wynosi 3 (15%/5% = 3), co oznacza, że model jest trzy razy skuteczniejszy od losowego wyboru.\n",
    "\n",
    "Proces uczenia maszynowego jest iteracyjny - często trzeba wracać\n",
    "do wcześniejszych etapów i wprowadzać modyfikacje na podstawie uzyskanych wyników.\n",
    "Istotne jest zrozumienie tzw. \"kontekstu biznesowego\" (jak zawsze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlEGAySVDPWW"
   },
   "source": [
    "### Najważniejsze wskaźniki używane do oceny modeli regresyjnych.\n",
    "\n",
    "1. \"Mean Squared Error (MSE)\" - błąd średni kwadratowy:\n",
    "\n",
    "- Obliczany jako średnia z kwadratów różnic między wartościami przewidzianymi a rzeczywistymi\n",
    "- Mocno penalizuje duże błędy poprzez podnoszenie do kwadratu\n",
    "- Zawsze przyjmuje wartości nieujemne; im bliżej 0, tym lepiej\n",
    "- Ma tę samą jednostkę co dane wejściowe podniesione do kwadratu\n",
    "\n",
    "\n",
    "2. \"Root Mean Squared Error (RMSE)\" - (pierwiastek) błędu średnio kwadratowego\n",
    "\n",
    "- Z definicji jest to pierwiastek z MSE\n",
    "- Popularniejszy od MSE, bo wyrażony w tych samych jednostkach co zmienna zależna\n",
    "- Łatwiejszy w interpretacji niż MSE\n",
    "- Również zawsze nieujemny; im bliżej 0, tym lepiej\n",
    "\n",
    "\n",
    "3. \"Mean Absolute Error (MAE)\" - średni błąd bezwzględny:\n",
    "\n",
    "- Obliczany jest jako średnia z wartości bezwzględnych różnic między przewidywaniami a wartościami rzeczywistymi\n",
    "\n",
    "- Mniej czuły na wartości odstające niż MSE/RMSE\n",
    "- Łatwy w interpretacji - pokazuje średnią wielkość błędu w jednostkach zmiennej zależnej\n",
    "- Zawsze nieujemny; im bliżej 0, tym lepiej\n",
    "\n",
    "4. Współczynnik R-kwadrat ($R^2$) -\n",
    "\n",
    "- Pokazuje, jaki procent zmienności zmiennej zależnej jest wyjaśniany przez model\n",
    "- Przyjmuje wartości od 0 do 1 (lub 0-100%)\n",
    "- Im bliżej 1, tym lepiej model opisuje dane\n",
    "- Może być mylący przy porównywaniu modeli o różnej złożoności\n",
    "\n",
    "\n",
    "5. Skorygowany współczynnik R-kwadrat (\"Adjusted R²\") -\n",
    "\n",
    "- Modyfikacja R² uwzględniająca liczbę zmiennych w modelu\n",
    "- Penalizuje dodawanie zbędnych zmiennych\n",
    "- Lepszy niż zwykły R² przy porównywaniu modeli o różnej liczbie zmiennych\n",
    "- Może przyjmować wartości ujemne\n",
    "\n",
    "6. MAPE (Mean Absolute Percentage Error) - średni bezwzględny błąd procentowy.\n",
    "\n",
    "- Wyrażony w procentach\n",
    "- Przydatny gdy chcemy porównać błędy dla różnych skal danych\n",
    "- Problematyczny gdy wartości rzeczywiste są bliskie zeru\n",
    "- Łatwy w komunikacji dla nietechnicznych odbiorców\n",
    "\n",
    "7. \"Explained Variance Score:\n",
    "\n",
    "- Mierzy, w jakim stopniu model uwzględnia wariancję w danych\n",
    "- Wartość 1.0 oznacza idealne dopasowanie\n",
    "- Może być ujemny dla bardzo złych modeli\n",
    "- Pomocny w wykrywaniu błędów systematycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UdqsyVqUTCA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPfF2Rh3eq4fFlelYvpdYXX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
